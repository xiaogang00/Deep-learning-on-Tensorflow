{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@author: huangyongye <br/>\n",
    "@creat_date: 2017-03-09 <br/>\n",
    "通过本例，你可以了解到单层 LSTM 的实现，多层 LSTM 的实现。输入输出数据的格式。 RNN 的 dropout layer 的实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "(55000, 784)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.contrib import rnn\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# 设置 GPU 按需增长\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "# 首先导入数据，看一下数据的形式\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "print mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ** 一、首先设置好模型用到的各个超参数 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "# 在训练和测试的时候，我们想用不同的 batch_size.所以采用占位符的方式\n",
    "batch_size = tf.placeholder(tf.int32)  # 注意类型必须为 tf.int32\n",
    "# batch_size = 128\n",
    "\n",
    "# 每个时刻的输入特征是28维的，就是每个时刻输入一行，一行有 28 个像素\n",
    "input_size = 28\n",
    "# 时序持续长度为28，即每做一次预测，需要先输入28行\n",
    "timestep_size = 28\n",
    "# 隐含层的数量\n",
    "hidden_size = 256\n",
    "# LSTM layer 的层数\n",
    "layer_num = 3\n",
    "# 最后输出分类类别数量，如果是回归预测的话应该是 1\n",
    "class_num = 10\n",
    "\n",
    "_X = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, class_num])\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ** 二、开始搭建 LSTM 模型，其实普通 RNNs 模型也一样 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 把784个点的字符信息还原成 28 * 28 的图片\n",
    "# 下面几个步骤是实现 RNN / LSTM 的关键\n",
    "####################################################################\n",
    "# **步骤1：RNN 的输入shape = (batch_size, timestep_size, input_size) \n",
    "X = tf.reshape(_X, [-1, 28, 28])\n",
    "\n",
    "# **步骤2：定义一层 LSTM_cell，只需要说明 hidden_size, 它会自动匹配输入的 X 的维度\n",
    "lstm_cell = rnn.BasicLSTMCell(num_units=hidden_size, forget_bias=1.0, state_is_tuple=True)\n",
    "\n",
    "# **步骤3：添加 dropout layer, 一般只设置 output_keep_prob\n",
    "lstm_cell = rnn.DropoutWrapper(cell=lstm_cell, input_keep_prob=1.0, output_keep_prob=keep_prob)\n",
    "\n",
    "# **步骤4：调用 MultiRNNCell 来实现多层 LSTM\n",
    "mlstm_cell = rnn.MultiRNNCell([lstm_cell] * layer_num, state_is_tuple=True)\n",
    "\n",
    "# **步骤5：用全零来初始化state\n",
    "init_state = mlstm_cell.zero_state(batch_size, dtype=tf.float32)\n",
    "\n",
    "# **步骤6：方法一，调用 dynamic_rnn() 来让我们构建好的网络运行起来\n",
    "# ** 当 time_major==False 时， outputs.shape = [batch_size, timestep_size, hidden_size] \n",
    "# ** 所以，可以取 h_state = outputs[:, -1, :] 作为最后输出\n",
    "# ** state.shape = [layer_num, 2, batch_size, hidden_size], \n",
    "# ** 或者，可以取 h_state = state[-1][1] 作为最后输出\n",
    "# ** 最后输出维度是 [batch_size, hidden_size]\n",
    "# outputs, state = tf.nn.dynamic_rnn(mlstm_cell, inputs=X, initial_state=init_state, time_major=False)\n",
    "# h_state = state[-1][1]\n",
    "\n",
    "# *************** 为了更好的理解 LSTM 工作原理，我们把上面 步骤6 中的函数自己来实现 ***************\n",
    "# 通过查看文档你会发现， RNNCell 都提供了一个 __call__()函数，我们可以用它来展开实现LSTM按时间步迭代。\n",
    "# **步骤6：方法二，按时间步展开计算\n",
    "outputs = list()\n",
    "state = init_state\n",
    "with tf.variable_scope('RNN'):\n",
    "    for timestep in range(timestep_size):\n",
    "        if timestep > 0:\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "        # 这里的state保存了每一层 LSTM 的状态\n",
    "        (cell_output, state) = mlstm_cell(X[:, timestep, :], state)\n",
    "        outputs.append(cell_output)\n",
    "h_state = outputs[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ** 三、最后设置 loss function 和 优化器，展开训练并完成测试 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter0, step 200, training accuracy 0.882812\n",
      "Iter0, step 400, training accuracy 0.976562\n",
      "Iter1, step 600, training accuracy 0.9375\n",
      "Iter1, step 800, training accuracy 0.976562\n",
      "Iter2, step 1000, training accuracy 0.984375\n",
      "test accuracy 0.9781\n"
     ]
    }
   ],
   "source": [
    "############################################################################\n",
    "# 以下部分其实和之前写的多层 CNNs 来实现 MNIST 分类是一样的。\n",
    "# 只是在测试的时候也要设置一样的 batch_size.\n",
    "\n",
    "# 上面 LSTM 部分的输出会是一个 [hidden_size] 的tensor，我们要分类的话，还需要接一个 softmax 层\n",
    "# 首先定义 softmax 的连接权重矩阵和偏置\n",
    "# out_W = tf.placeholder(tf.float32, [hidden_size, class_num], name='out_Weights')\n",
    "# out_bias = tf.placeholder(tf.float32, [class_num], name='out_bias')\n",
    "# 开始训练和测试\n",
    "W = tf.Variable(tf.truncated_normal([hidden_size, class_num], stddev=0.1), dtype=tf.float32)\n",
    "bias = tf.Variable(tf.constant(0.1,shape=[class_num]), dtype=tf.float32)\n",
    "y_pre = tf.nn.softmax(tf.matmul(h_state, W) + bias)\n",
    "\n",
    "\n",
    "# 损失和评估函数\n",
    "cross_entropy = -tf.reduce_mean(y * tf.log(y_pre))\n",
    "train_op = tf.train.AdamOptimizer(lr).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_pre,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(1000):\n",
    "    _batch_size = 128\n",
    "    batch = mnist.train.next_batch(_batch_size)\n",
    "    if (i+1)%200 == 0:\n",
    "        train_accuracy = sess.run(accuracy, feed_dict={\n",
    "            _X:batch[0], y: batch[1], keep_prob: 1.0, batch_size: _batch_size})\n",
    "        # 已经迭代完成的 epoch 数: mnist.train.epochs_completed\n",
    "        print \"Iter%d, step %d, training accuracy %g\" % ( mnist.train.epochs_completed, (i+1), train_accuracy)\n",
    "    sess.run(train_op, feed_dict={_X: batch[0], y: batch[1], keep_prob: 0.5, batch_size: _batch_size})\n",
    "\n",
    "# 计算测试数据的准确率\n",
    "print \"test accuracy %g\"% sess.run(accuracy, feed_dict={\n",
    "    _X: mnist.test.images, y: mnist.test.labels, keep_prob: 1.0, batch_size:mnist.test.images.shape[0]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们一共只迭代不到5个epoch，在测试集上就已经达到了0.9825的准确率，可以看出来 LSTM 在做这个字符分类的任务上还是比较有效的，而且我们最后一次性对 10000 张测试图片进行预测，才占了 725 MiB 的显存。而我们在之前的两层 CNNs 网络中，预测 10000 张图片一共用了 8721 MiB 的显存，差了整整 12 倍呀！！ 这主要是因为 RNN/LSTM 网络中，每个时间步所用的权值矩阵都是共享的，可以通过前面介绍的 LSTM 的网络结构分析一下，整个网络的参数非常少。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四、可视化看看 LSTM 的是怎么做分类的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "毕竟 LSTM 更多的是用来做时序相关的问题，要么是文本，要么是序列预测之类的，所以很难像 CNNs 一样非常直观地看到每一层中特征的变化。在这里，我想通过可视化的方式来帮助大家理解 LSTM 是怎么样一步一步地把图片正确的给分类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (5, 784) (5, 10)\n",
      "_outputs.shape = (28, 5, 256)\n",
      "arr_state.shape = (3, 2, 5, 256)\n"
     ]
    }
   ],
   "source": [
    "# 手写的结果 shape\n",
    "_batch_size = 5\n",
    "X_batch, y_batch = mnist.test.next_batch(_batch_size)\n",
    "print X_batch.shape, y_batch.shape\n",
    "_outputs, _state = np.array(sess.run([outputs, state],feed_dict={\n",
    "            _X: X_batch, y: y_batch, keep_prob: 1.0, batch_size: _batch_size}))\n",
    "print '_outputs.shape =', np.asarray(_outputs).shape\n",
    "print 'arr_state.shape =', np.asarray(_state).shape\n",
    "# 可见 outputs.shape = [ batch_size, timestep_size, hidden_size]\n",
    "# state.shape = [layer_num, 2, batch_size, hidden_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 784) (5, 10)\n",
      "_outputs.shape= (5, 28, 256)\n",
      "arr_state.shape= (3, 2, 5, 256)\n"
     ]
    }
   ],
   "source": [
    "# 使用 dynamic_rnn() 的结果。\n",
    "_batch_size = 5\n",
    "X_batch, y_batch = mnist.test.next_batch(_batch_size)\n",
    "print X_batch.shape, y_batch.shape\n",
    "_outputs, _state = np.array(sess.run([outputs, state],feed_dict={\n",
    "            _X: X_batch, y: y_batch, keep_prob: 1.0, batch_size: _batch_size}))\n",
    "print '_outputs.shape =', _outputs.shape\n",
    "print 'arr_state.shape =', np.asarray(_state).shape\n",
    "# 可见 outputs.shape = [ batch_size, timestep_size, hidden_size]\n",
    "# state.shape = [layer_num, 2, batch_size, hidden_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看下面我找了一个字符 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print mnist.train.labels[14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们先来看看这个字符样子,上半部分还挺像 2 来的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc343e6f690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X3 = mnist.train.images[14]\n",
    "img3 = X3.reshape([28, 28])\n",
    "plt.imshow(img3, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们看看在分类的时候，一行一行地输入，分为各个类别的概率会是什么样子的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 1, 256)\n",
      "(28, 256)\n"
     ]
    }
   ],
   "source": [
    "X3.shape = [-1, 784]\n",
    "y_batch = mnist.train.labels[0]\n",
    "y_batch.shape = [-1, class_num]\n",
    "\n",
    "X3_outputs = np.array(sess.run(outputs, feed_dict={\n",
    "            _X: X3, y: y_batch, keep_prob: 1.0, batch_size: 1}))\n",
    "print X3_outputs.shape\n",
    "X3_outputs.shape = [28, hidden_size]\n",
    "print X3_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRvgBYoQfIEb4AWKEHyBG+AFifgMXRsQjQtzy9QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc343e56d50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h_W = sess.run(W, feed_dict={\n",
    "            _X:X3, y: y_batch, keep_prob: 1.0, batch_size: 1})\n",
    "h_bias = sess.run(bias, feed_dict={\n",
    "            _X:X3, y: y_batch, keep_prob: 1.0, batch_size: 1})\n",
    "h_bias.shape = [-1, 10]\n",
    "\n",
    "bar_index = range(class_num)\n",
    "for i in xrange(X3_outputs.shape[0]):\n",
    "    plt.subplot(7, 4, i+1)\n",
    "    X3_h_shate = X3_outputs[i, :].reshape([-1, hidden_size])\n",
    "    pro = sess.run(tf.nn.softmax(tf.matmul(X3_h_shate, h_W) + h_bias))\n",
    "    plt.bar(bar_index, pro[0], width=0.2 , align='center')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在上面的图中，为了更清楚地看到线条的变化，我把坐标都去了，每一行显示了 4 个图，共有 7 行，表示了一行一行读取过程中，模型对字符的识别。可以看到，在只看到前面的几行像素时，模型根本认不出来是什么字符，随着看到的像素越来越多，最后就基本确定了它是字符 3."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
